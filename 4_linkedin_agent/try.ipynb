{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from linkedin_jobs_scraper import LinkedinScraper, events, query, filters\n",
    "from resume_matcher.matching import resume_job_desc_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## LinkedIn Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_RESULTS = []\n",
    "\n",
    "def on_data(data):\n",
    "    JOB_RESULTS.append({\n",
    "        \"title\": data.title,\n",
    "        \"company\": data.company,\n",
    "        \"location\": data.location,\n",
    "        # \"description\": data.description,\n",
    "        \"link\": data.link,\n",
    "        \"date\": data.date\n",
    "    })\n",
    "\n",
    "def on_error(error):\n",
    "    print('[ON_ERROR]', error)\n",
    "\n",
    "def on_end():\n",
    "    print('[END]')\n",
    "\n",
    "def scrape_linkedin_jobs(search_term, location = 'Remote', num_jobs = 10):\n",
    "    global JOB_RESULTS\n",
    "    scraper = LinkedinScraper(\n",
    "        chrome_executable_path=None,\n",
    "        # chrome_driver_path=None,\n",
    "        headless=True,\n",
    "        max_workers=1,\n",
    "        slow_mo=0.5,\n",
    "        page_load_timeout=20,\n",
    "        # browser_user_agent=None,\n",
    "        # proxy=None\n",
    "    )\n",
    "    scraper.on(events.Events.DATA, on_data)\n",
    "    scraper.on(events.Events.ERROR, on_error)\n",
    "    scraper.on(events.Events.END, on_end)\n",
    "\n",
    "    queries = [\n",
    "        query.Query(\n",
    "            query=search_term,\n",
    "            options= query.QueryOptions(\n",
    "                locations = [location],\n",
    "                apply_link = True,\n",
    "                limit = num_jobs,\n",
    "                filters = query.QueryFilters(\n",
    "                    experience=[filters.ExperienceLevelFilters.ENTRY_LEVEL],\n",
    "                    type=[filters.TypeFilters.FULL_TIME]\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "    \n",
    "    scraper.run(queries)\n",
    "    time.sleep(2)\n",
    "    return JOB_RESULTS.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_QUERY = \"AI Engineer\"    # Edit as desired\n",
    "JOB_LOCATION = \"Remote\"\n",
    "NUM_JOBS = 10\n",
    "\n",
    "scraped_jobs = scrape_linkedin_jobs(JOB_QUERY, location=JOB_LOCATION, num_jobs=NUM_JOBS)\n",
    "\n",
    "print(f\"Scraped {len(scraped_jobs)} jobs.\")\n",
    "print(scraped_jobs)  # Display first 5 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
